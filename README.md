# Data-Driven Particle Position Estimation

This project explores a machine learning approach to estimate particle positions in a two-dimensional space using signals from a Resistive Silicon Detector (RSD). The pipeline leverages regression models to deduce positions based on signal data collected during particle events.

## ğŸ“‹ Table of Contents

1. [ğŸ” Problem Overview](#-problem-overview)  
2. [ğŸ“‚ Dataset](#-dataset)  
4. [ğŸ› ï¸ Proposed Approach](#-proposed-approach)  
5. [ğŸ“Š Results](#-results)  
6. [âš¡ Limitations & Future Developments](#-limitations--future-developments)

## ğŸ” Problem Overview
 
Particle position estimation is a critical task in particle physics and involves detecting particles using an RSD. The dataset consists of events, each corresponding to a particle crossing the sensor and generating signals on 12 metallic pads. These signals include metrics like positive and negative peaks, time delay, area, and RMS values. However, the data also contains noise, making accurate predictions challenging.

## ğŸ“‚ Dataset

The dataset includes readings for 18 features per event (derived from hardware limitations), but only 12 pads are directly relevant. Key features:
	â€¢	Pmax: Positive peak magnitude (mV)
	â€¢	Negpmax: Negative peak magnitude (mV)
	â€¢	Tmax: Time delay for the positive peak (ns)
	â€¢	Area: Area under the signal
	â€¢	RMS: Root mean square value

Outlier detection and feature correlation analysis were performed to refine the dataset.

## ğŸ› ï¸ Proposed Approach

1. Preprocessing

	â€¢	Feature Selection: Removed noisy or redundant pads (e.g., Pads 0, 7, 12, 16, 17) based on correlation analysis.
	â€¢	Normalization: Applied standard normalization to ensure consistent feature scaling.
	â€¢	Dimensionality Reduction: Retained only highly correlated features (e.g., Pmax over Area).

2. Model Selection

Two tree-based models were employed:
	â€¢	Random Forest Regressor
	â€¢	Extra Trees Regressor

These models are robust against outliers and suitable for handling large datasets.

3. Hyperparameter Tuning

Key hyperparameters (e.g., number of estimators, maximum depth, min samples split) were optimized using Euclidean distance as the evaluation metric.

## ğŸ“Š Results

The project achieved significant improvements over naive solutions:
	â€¢	Random Solution: Euclidean distance = 209.847
	â€¢	Naive Solution: Euclidean distance = 8.897
	â€¢	Our Model: Euclidean distance â‰ˆ 4.734

## âš¡ Limitations & Future Developments

Limitations

â€¢	Limited computational resources constrained hyperparameter optimization.
â€¢	Lack of domain expertise impacted feature selection.

Future Developments

â€¢	Incorporate Gradient Boosting and Neural Networks to explore nonlinear relationships.
â€¢	Enhance feature engineering with better domain insights.
â€¢	Utilize distributed computing for hyperparameter tuning.
